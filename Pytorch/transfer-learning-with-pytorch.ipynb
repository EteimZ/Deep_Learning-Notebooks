{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning\n\nIn this Notebook, I will use Transfer Learning to classify images of Dogs&Cats. There are two methods of transfer learning:\n\n**Feature Extraction**: This method involves getting a pretrained network, freezing the weights of the convolutional layers and then replacing the fully connected layer with a new one.\n\n**Fine-Tuning**: Similar to feature extraction except most of the convolutional layers are unfreezed and their weight can be updated.\n\nThe Model is a **VGG-16** Nueral Network with pretrained weights from ImageNet dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/cat-and-dog/'\n\nimage_datasets = {\n    'train': \n    datasets.ImageFolder(data_dir + 'training_set/training_set', data_transforms['train']),\n    'val': \n    datasets.ImageFolder(data_dir + 'test_set/test_set', data_transforms['val'])\n}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=0),\n    'val':\n    torch.utils.data.DataLoader(image_datasets['val'],\n                                batch_size=32,\n                                shuffle=False,\n                                num_workers=0)\n}\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = image_datasets['train'].classes\nclass_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Loop\ndef traineval(model, num_epochs, criterion, optimizer):\n    \n    losses = {'train' : [], 'valid': []}\n    accs = {'train' : [], 'valid': []}\n    # keeping-track-of-losses    \n    train_samples,train_correct,valid_samples, valid_correct = 0,0,0,0\n    \n\n    for epoch in range(1, num_epochs + 1):\n        # keep-track-of-training-and-validation-loss\n        train_loss = 0.0\n        valid_loss = 0.0\n    \n        # training-the-model\n        model.train()\n        for data, target in dataloaders['train']:\n            # move-tensors-to-GPU \n            data = data.to(device)\n            target = target.to(device)\n        \n            # clear-the-gradients-of-all-optimized-variables\n            optimizer.zero_grad()\n            # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n            output = model(data)\n            _, predicted = torch.max(output, 1)\n            train_samples += target.size(0)\n            train_correct += (predicted == target).sum().item()\n        \n            train_acc = 100.0 * train_correct / train_samples\n            \n            # calculate-the-batch-loss\n            loss = criterion(output, target)\n            \n            # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n            loss.backward()\n            \n            # perform-a-single-optimization-step (parameter-update)\n            optimizer.step()\n            \n            # update-training-loss\n            train_loss += loss.item() * data.size(0)\n        \n        \n        model.eval()\n        for data, target in dataloaders['val']:\n        \n            data = data.to(device)\n            target = target.to(device)\n        \n            output = model(data)\n            _, predicted = torch.max(output, 1)\n            valid_samples += target.size(0)\n            valid_correct += (predicted == target).sum().item()\n        \n            val_acc = 100.0 * valid_correct / valid_samples\n        \n            loss = criterion(output, target)\n        \n            # update-average-validation-loss \n            valid_loss += loss.item() * data.size(0)\n    \n        # calculate-average-losses and Accuracies\n        train_loss = train_loss/len(dataloaders['train'].sampler)\n        valid_loss = valid_loss/len(dataloaders['val'].sampler)\n    \n    \n        losses['train'].append(train_loss)\n        losses['valid'].append(valid_loss)\n        accs['train'].append(train_acc)\n        accs['valid'].append(val_acc)\n        \n        print('Epoch: {} Training Loss: {:.6f} Validation Loss: {:.6f} Training accuracy: {:.6f} Valid accuracy: {:.6f}'.format(\n        epoch, train_loss, valid_loss, train_acc, val_acc))\n        \n    return losses, accs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Loss & Accuracy Graph\n\ndef Graph(losses, accs, num_epochs):\n    epochs = [x for x in range(1,num_epochs+1)]\n    \n    plt.figure(figsize = (10,5))\n    plt.subplot(1,2,1)\n    \n    #Loss\n    plt.title(\"Loss\")\n    plt.plot(epochs, losses['train'] , label='Training loss')\n    plt.plot(epochs, losses['valid'] , label='Validation loss')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend(frameon=False)\n\n    plt.subplot(1,2,2)\n    \n    #Accuracy\n    plt.title(\"Accuracy\")\n    plt.plot(epochs, accs['train'], label='Training Accuracy')\n    plt.plot(epochs, accs['valid'], label='Validation Accuracy')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Acc\")\n    plt.legend(frameon=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Model\nmodel =  models.vgg16(pretrained=False)\n\n#Freeze conv layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n#Load Weights\nmodel.load_state_dict(torch.load(\"../input/vgg16/vgg16.pth\"))\n\nprint(\"Original VGG16 Model:\\n\", model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding New fully connected layer\nmodel.classifier = nn.Sequential(\n                      nn.Linear(25088,256),\n                      nn.ReLU(),\n                      nn.Dropout(0.5),\n                      nn.Linear(256,2)\n                   )\n\nprint(\"New VGG16 Model:\\n\", model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)\n\nnum_epochs = 25\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlosses, accs = traineval(model,num_epochs,criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Graph(losses, accs, num_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = './ExtractedCatDog.pth'\ntorch.save(model.state_dict(), PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine-Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Model\nfine_model =  models.vgg16(pretrained=False)\n\n# Freeze the first 4 Conv blocks\nfor i, param in enumerate(fine_model.parameters()):\n    param.requires_grad = False\n    # UnFreeze the 5th Conv block\n    if i >= 20:\n        param.requires_grad = True\n\n#Load Weights\nfine_model.load_state_dict(torch.load(\"../input/vgg16/vgg16.pth\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding New fully connected layer\nfine_model.classifier = nn.Sequential(\n                      nn.Linear(25088,256),\n                      nn.ReLU(),\n                      nn.Dropout(0.5),\n                      nn.Linear(256,2)\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking trainable parameters\nfor name, param in fine_model.named_parameters():\n    if param.requires_grad == True:\n        print(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_model = fine_model.to(device)\n\nnum_epochs = 25\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(fine_model.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlosses, accs = traineval(fine_model,num_epochs,criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Graph(losses, accs, num_epochs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}